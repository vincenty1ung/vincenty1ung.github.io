package scripts

import (
	"bytes"
	"crypto/md5"
	"encoding/json"
	"fmt"
	"io"
	"io/fs"
	"os"
	"path/filepath"
	"regexp"
	"sort"
	"strings"
	"sync"
	"time"
)

// Configuration
const (
	ProjectRoot = "../" // Assuming script is run from scripts/ directory
	ImgDir      = "web/photography/gallery_images"
	OutputFile  = "web/photography/photos.json"

	// Path prefixes
	WebPhotographyPrefix = "web/photography/"

	// File extensions
	ExtJPG  = ".jpg"
	ExtJPEG = ".jpeg"
	ExtPNG  = ".png"
	ExtWebP = ".webp"

	// Date formats
	DateFormatYMD     = "%s-%s-%s"
	DateFormatDefault = "%s-01-01"
	DefaultMonth      = "01"
	DefaultDay        = "01"

	// Concurrency
	MaxConcurrency = 10
)

// Photo represents a single photo entry
type Photo struct {
	Filename  string                 `json:"filename"`
	Path      string                 `json:"path"`
	Thumbnail string                 `json:"thumbnail"`
	Alt       string                 `json:"alt"`
	Year      string                 `json:"year"`
	Month     string                 `json:"month"`
	Date      string                 `json:"date"` // YYYY-MM-DD for sorting
	Width     int                    `json:"width,omitempty"`
	Height    int                    `json:"height,omitempty"`
	Exif      map[string]interface{} `json:"exif,omitempty"` // Complete EXIF data
	Hash      string                 `json:"hash,omitempty"` // File hash for caching
	Timestamp int64                  `json:"-"`              // Timestamp for sorting
}

// YearAlbum represents a collection of photos for a specific year
type YearAlbum struct {
	Year   string  `json:"year"`
	Photos []Photo `json:"photos"`
}

// PhotoProcessor handles the processing of photos
type PhotoProcessor struct {
	RootDir        string
	ImgDirPath     string
	R2Client       *R2Client
	ThumbnailBase  string
	ExistingPhotos map[string]Photo // Key: Filename
	NewPhotos      []Photo
	Mutex          sync.Mutex
	DateRegex      *regexp.Regexp
}

// NewPhotoProcessor creates a new PhotoProcessor
func NewPhotoProcessor() (*PhotoProcessor, error) {
	rootDir, err := os.Getwd()
	if err != nil {
		return nil, fmt.Errorf("error getting current working directory: %w", err)
	}

	// Initialize R2 client
	var r2Client *R2Client
	var thumbnailBase string

	r2Config, err := LoadR2Config()
	if err != nil {
		fmt.Printf("‚ö† Warning: R2 configuration load failed: %v\n", err)
		fmt.Println("Using default/empty configuration...")
	} else {
		thumbnailBase = fmt.Sprintf(
			"%s/%s%s",
			strings.TrimRight(r2Config.CDNUrl, "/"),
			r2Config.BasePrefix,
			r2Config.ThumbnailPrefix,
		)
		r2Client, err = NewR2Client(r2Config)
		if err != nil {
			fmt.Printf("‚ö† Warning: Failed to create R2 client: %v\n", err)
		} else {
			fmt.Println("‚úì R2 client initialized successfully")
		}
	}

	return &PhotoProcessor{
		RootDir:        rootDir,
		ImgDirPath:     filepath.Join(rootDir, ImgDir),
		R2Client:       r2Client,
		ThumbnailBase:  thumbnailBase,
		ExistingPhotos: make(map[string]Photo),
		DateRegex:      regexp.MustCompile(`DSC_(\d{4})-(\d{2})-(\d{2})`),
	}, nil
}

// LoadExistingMetadata loads existing photos.json
func (p *PhotoProcessor) LoadExistingMetadata() ([]byte, error) {
	var content []byte
	outputFilePath := filepath.Join(p.RootDir, OutputFile)
	if _, err := os.Stat(outputFilePath); err == nil {
		content, err = os.ReadFile(outputFilePath)
		if err != nil {
			return nil, err
		}

		var albums []YearAlbum
		if err := json.Unmarshal(content, &albums); err == nil {
			for _, album := range albums {
				for _, photo := range album.Photos {
					// Restore Timestamp from Exif if available
					if val, ok := photo.Exif["DateTimeOriginal"]; ok {
						if dateStr, ok := val.(string); ok {
							if t, err := time.Parse("2006:01:02 15:04:05", dateStr); err == nil {
								photo.Timestamp = t.Unix()
							}
						}
					}
					p.ExistingPhotos[photo.Filename] = photo
				}
			}
			fmt.Printf("üü¢ Loaded existing metadata for %d photos.\n", len(p.ExistingPhotos))
		}
	}
	return content, nil
}

// calculateFileHash calculates MD5 hash of a file
func calculateFileHash(filePath string) (string, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return "", err
	}
	defer func(file *os.File) {
		err := file.Close()
		if err != nil {
			fmt.Println("Failed to close file.")
		}
	}(file)

	hash := md5.New()
	if _, err := io.Copy(hash, file); err != nil {
		return "", err
	}

	return fmt.Sprintf("%x", hash.Sum(nil)), nil
}

// processPhoto processes a single photo
func (p *PhotoProcessor) processPhoto(path string, yearDirName string) (Photo, error) {
	filename := filepath.Base(path)
	filenameNoExt := strings.TrimSuffix(filename, filepath.Ext(filename))

	// Calculate hash
	hash, err := calculateFileHash(path)
	if err != nil {
		return Photo{}, fmt.Errorf("failed to calculate hash: %w", err)
	}

	// Check if photo exists and hash matches
	if existing, ok := p.ExistingPhotos[filename]; ok {
		// Á¨¨‰∏ÄÊ¨°ÊòØÁõ∏ÂêåÁöÑ
		if existing.Hash == hash {
			// if true {
			// 	existing.Hash = hash
			// Photo hasn't changed, return existing data
			// But ensure path is correct (in case of URL changes, though hash check implies content same)
			// We might want to re-verify R2 existence if we were being very strict, but for perf we skip
			// fmt.Printf("Skipping unchanged photo: %s\n", filename)
			return existing, nil
		}
	}

	// New or modified photo
	fmt.Printf("üü¢ Processing %s...\n", filename)

	relPath, _ := filepath.Rel(p.RootDir, path)
	webPath := strings.ReplaceAll(relPath, "\\", "/")
	if after, ok := strings.CutPrefix(webPath, WebPhotographyPrefix); ok {
		webPath = after
	}

	var finalPath, finalThumbnail string

	// R2 Upload Logic
	if p.R2Client != nil {
		// 1. Upload Original
		originalKey := fmt.Sprintf("%s%s%s", p.R2Client.config.BasePrefix, p.R2Client.config.OriginalPrefix, filename)
		// We could check existence, but since hash changed or it's new, we should probably upload
		// Or we can check if it exists to avoid re-uploading if only local metadata changed?
		// For simplicity/safety, if hash changed, we upload.

		if err := p.R2Client.UploadFile(path, originalKey, "public, max-age=31536000"); err != nil {
			fmt.Printf("‚ùå Failed to upload original %s: %v\n", filename, err)
			finalPath = webPath
		} else {
			finalPath = p.R2Client.GetCDNUrl(originalKey)
		}

		// 2. Upload Thumbnail
		thumbnailKey := fmt.Sprintf(
			"%s%s%s%s", p.R2Client.config.BasePrefix, p.R2Client.config.ThumbnailPrefix, filenameNoExt, ExtWebP,
		)
		thumbnailData, err := GenerateThumbnail(path, DefaultThumbnailConfig())
		if err != nil {
			fmt.Printf("‚ùå Failed to generate thumbnail for %s: %v\n", filename, err)
			finalThumbnail = p.ThumbnailBase + filenameNoExt + ".webp"
		} else {
			if err := p.R2Client.UploadBytes(
				thumbnailData, thumbnailKey, "image/webp", "public, max-age=31536000",
			); err != nil {
				fmt.Printf("‚ùå Failed to upload thumbnail for %s: %v\n", filename, err)
				finalThumbnail = p.ThumbnailBase + filenameNoExt + ".webp"
			} else {
				finalThumbnail = p.R2Client.GetCDNUrl(thumbnailKey)
			}
		}
	} else {
		finalPath = webPath
		finalThumbnail = p.ThumbnailBase + filenameNoExt + ".webp"
	}

	// Extract EXIF using configured extractor
	exifData, width, height, dateTaken, err := GetExifExtractor().Extract(path)

	var photoYear, month, dateStr string
	var timestamp int64

	if err == nil && !dateTaken.IsZero() {
		photoYear = fmt.Sprintf("%04d", dateTaken.Year())
		month = fmt.Sprintf("%02d", dateTaken.Month())
		dateStr = dateTaken.Format("2006-01-02")
		timestamp = dateTaken.Unix()
	} else {
		// Fallback to filename
		matches := p.DateRegex.FindStringSubmatch(filename)
		if len(matches) >= 4 {
			photoYear = matches[1]
			month = matches[2]
			dateStr = fmt.Sprintf(DateFormatYMD, matches[1], matches[2], matches[3])
		} else {
			photoYear = yearDirName
			month = DefaultMonth
			dateStr = fmt.Sprintf(DateFormatDefault, yearDirName)
		}
		if err != nil {
			fmt.Printf("‚ö† EXIF extraction failed for %s: %v\n", filename, err)
		}
	}

	// Create Photo struct
	photo := Photo{
		Filename:  filename,
		Path:      finalPath,
		Thumbnail: finalThumbnail,
		Alt:       "", // Preserve alt if exists?
		Year:      photoYear,
		Month:     month,
		Date:      dateStr,
		Width:     width,
		Height:    height,
		Exif:      exifData,
		Hash:      hash,
		Timestamp: timestamp,
	}

	// Preserve Alt from existing if available
	if existing, ok := p.ExistingPhotos[filename]; ok {
		photo.Alt = existing.Alt
	}

	return photo, nil
}

func UpdatePhotosHandler() {
	processor, err := NewPhotoProcessor()
	if err != nil {
		fmt.Printf("Error initializing processor: %v\n", err)
		os.Exit(1)
	}
	var existingContent []byte

	if existingContent, err = processor.LoadExistingMetadata(); err != nil {
		fmt.Printf("Warning: Failed to load existing metadata: %v\n", err)
	}

	// Collect all image files
	type Job struct {
		Path    string
		YearDir string
	}
	var jobs []Job

	entries, err := os.ReadDir(processor.ImgDirPath)
	if err != nil {
		fmt.Printf("Error reading image directory: %v\n", err)
		os.Exit(1)
	}

	for _, entry := range entries {
		if !entry.IsDir() {
			continue
		}
		yearDir := filepath.Join(processor.ImgDirPath, entry.Name())

		err := filepath.WalkDir(
			yearDir, func(path string, d fs.DirEntry, err error) error {
				if err != nil || d.IsDir() {
					return err
				}
				ext := strings.ToLower(filepath.Ext(d.Name()))
				if ext == ExtJPG || ext == ExtJPEG || ext == ExtPNG || ext == ExtWebP {
					jobs = append(jobs, Job{Path: path, YearDir: entry.Name()})
				}
				return nil
			},
		)
		if err != nil {
			fmt.Printf("Error walking directory %s: %v\n", yearDir, err)
		}
	}

	// Worker Pool
	jobsChan := make(chan Job, len(jobs))
	resultsChan := make(chan Photo, len(jobs))
	var wg sync.WaitGroup

	// Start workers
	numWorkers := MaxConcurrency
	if len(jobs) < numWorkers {
		numWorkers = len(jobs)
	}

	fmt.Printf("üü¢ Starting %d workers for %d photos...\n", numWorkers, len(jobs))

	for i := 0; i < numWorkers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for job := range jobsChan {
				photo, err := processor.processPhoto(job.Path, job.YearDir)
				if err != nil {
					fmt.Printf("Error processing %s: %v\n", filepath.Base(job.Path), err)
					continue
				}
				resultsChan <- photo
			}
		}()
	}

	// Send jobs
	for _, job := range jobs {
		jobsChan <- job
	}
	close(jobsChan)
	fmt.Println("‚úì ‰ªªÂä°ÂàÜÂèëÂÆåÊàê")

	// Wait for workers
	wg.Wait()
	fmt.Println("‚úì ‰ªªÂä°Â∑≤ÁªèÁªìÊùü")
	close(resultsChan)

	// Collect results
	var allPhotos []Photo
	for photo := range resultsChan {
		allPhotos = append(allPhotos, photo)
	}

	// Organize into albums
	albumsMap := make(map[string][]Photo)
	for _, p := range allPhotos {
		albumsMap[p.Year] = append(albumsMap[p.Year], p)
	}

	var newAlbums []YearAlbum
	for year, photos := range albumsMap {
		// Sort photos by date desc, then timestamp desc, then filename desc
		sort.Slice(
			photos, func(i, j int) bool {
				if photos[i].Date != photos[j].Date {
					return photos[i].Date > photos[j].Date
				}
				if photos[i].Timestamp != photos[j].Timestamp {
					return photos[i].Timestamp > photos[j].Timestamp
				}
				return photos[i].Filename > photos[j].Filename
			},
		)
		newAlbums = append(newAlbums, YearAlbum{Year: year, Photos: photos})
	}

	// Sort albums by year desc
	sort.Slice(
		newAlbums, func(i, j int) bool {
			return newAlbums[i].Year > newAlbums[j].Year
		},
	)

	// Identify deleted photos
	if processor.R2Client != nil {
		newPhotosMap := make(map[string]bool)
		for _, p := range allPhotos {
			newPhotosMap[p.Filename] = true
		}

		var keysToDelete []string
		for filename := range processor.ExistingPhotos {
			if !newPhotosMap[filename] {
				fmt.Printf("Marking for deletion: %s\n", filename)
				// Add original and thumbnail to delete list
				keysToDelete = append(
					keysToDelete,
					fmt.Sprintf(
						"%s%s%s", processor.R2Client.config.BasePrefix, processor.R2Client.config.OriginalPrefix,
						filename,
					),
					fmt.Sprintf(
						"%s%s%s%s", processor.R2Client.config.BasePrefix, processor.R2Client.config.ThumbnailPrefix,
						strings.TrimSuffix(filename, filepath.Ext(filename)), ExtWebP,
					),
				)
			}
		}

		if len(keysToDelete) > 0 {
			fmt.Printf("üü¢ Deleting %d orphaned files from R2...\n", len(keysToDelete))
			if err := processor.R2Client.DeleteObjects(keysToDelete); err != nil {
				fmt.Printf("Error deleting objects: %v\n", err)
			} else {
				fmt.Println("‚úì Successfully deleted orphaned files.")
			}
		}
	}

	// Write output
	jsonData, err := json.Marshal(newAlbums)
	if err != nil {
		fmt.Printf("Error marshaling JSON: %v\n", err)
		os.Exit(1)
	}

	outputFilePath := filepath.Join(processor.RootDir, OutputFile)

	// Check if content changed (ignoring order if possible, but simple byte check is fast)
	// Since we re-generated everything, byte comparison might fail if order changed slightly or timestamps
	// But we should write anyway if we processed updates.

	err = os.WriteFile(outputFilePath, jsonData, 0644)
	if err != nil {
		fmt.Printf("Error writing output file: %v\n", err)
		os.Exit(1)
	}

	// Create backup of existing file if it exists
	if len(existingContent) > 0 {
		backupPath := outputFilePath + "." + time.Now().Format("20060102_150405") + ".bak"
		if err := os.WriteFile(backupPath, existingContent, 0644); err != nil {
			fmt.Printf("Warning: Could not create backup of %s: %v\n", outputFilePath, err)
		} else {
			fmt.Printf("‚úì Backup created: %s\n", backupPath)
		}
	}

	// Check if content has changed
	if JSONEqual(existingContent, jsonData) {
		fmt.Println("‚úì photos.json has not changed. Skipping backup, file write, and R2 upload.")
		return
	}

	// Upload photos.json to R2
	if processor.R2Client != nil {
		jsonKey := fmt.Sprintf("%sphotos.json", processor.R2Client.config.BasePrefix)
		if err := processor.R2Client.UploadBytes(
			jsonData, jsonKey, "application/json", "public, max-age=720, must-revalidate",
		); err != nil {
			fmt.Printf("‚ùå Failed to upload photos.json: %v\n", err)
		} else {
			fmt.Printf("‚úì Uploaded photos.json to R2\n")
		}
	}

	fmt.Printf("Successfully updated photos.json with %d photos.\n", len(allPhotos))
}

// JSONEqual compares two JSON byte slices for equality, ignoring whitespace and key order
func JSONEqual(a, b []byte) bool {
	var j1, j2 interface{}
	if err := json.Unmarshal(a, &j1); err != nil {
		return false
	}
	if err := json.Unmarshal(b, &j2); err != nil {
		return false
	}

	// Re-marshal to ensure consistent formatting (e.g. sorted keys, no whitespace)
	// Use MarshalIndent for readability in diffs
	m1, err := json.MarshalIndent(j1, "", "  ")
	if err != nil {
		return false
	}
	m2, err := json.MarshalIndent(j2, "", "  ")
	if err != nil {
		return false
	}

	if !bytes.Equal(m1, m2) {
		fmt.Println("‚ö†Ô∏è JSON content differs. Writing to files for comparison...")
		_ = os.WriteFile("photos_old.json", m1, 0644)
		_ = os.WriteFile("photos_new.json", m2, 0644)
		fmt.Println("üëâ Please compare 'photos_old.json' and 'photos_new.json' to see the differences.")
		return false
	}

	return true
}
